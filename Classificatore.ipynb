{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****CON LOOP GIGANTE****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datas from: /Users/Riccardo/Desktop/Progetto Scalogrammi/Scalogrammi\n",
      "\n",
      "Loading complete!\n",
      "Datasets dimension:\n",
      "X shape: 618\n",
      "y shape: 618\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 1: - Random Seed: 6723\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.62s/trial, best loss: -0.8032258064516129]\n",
      "{'C': 0.05880829417442142, 'gamma': 0.26163731242677424, 'kernel': 1}\n",
      "{'C': 0.05880829417442142, 'gamma': 0.26163731242677424, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7124\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.7124 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 0.05880829417442142, 'gamma': 0.26163731242677424, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8452\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[38;5;208mTHAT'S A NEW BEST!!\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 2: - Random Seed: 366\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.60s/trial, best loss: -0.7935483870967742]\n",
      "{'C': 4.131860922125607, 'gamma': 0.12449251995882374, 'kernel': 1}\n",
      "{'C': 4.131860922125607, 'gamma': 0.12449251995882374, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8301\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8301 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 4.131860922125607, 'gamma': 0.12449251995882374, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7419\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 3: - Random Seed: 2594\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.7709677419354839]\n",
      "{'C': 5.102671847326659, 'gamma': 0.15012038378103296, 'kernel': 1}\n",
      "{'C': 5.102671847326659, 'gamma': 0.15012038378103296, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8301\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.9097\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[38;5;208mTHAT'S A NEW BEST!!\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 4: - Random Seed: 5779\n",
      "100%|██████████| 220/220 [05:49<00:00,  1.59s/trial, best loss: -0.7774193548387096]\n",
      "{'C': 0.5558713459499448, 'gamma': 15.1182501357312, 'kernel': 1}\n",
      "{'C': 0.5558713459499448, 'gamma': 15.1182501357312, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7908\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8516\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 5: - Random Seed: 5066\n",
      "100%|██████████| 220/220 [05:54<00:00,  1.61s/trial, best loss: -0.8419354838709677]\n",
      "{'C': 0.3738720166607507, 'gamma': 4.802750374089542, 'kernel': 1}\n",
      "{'C': 0.3738720166607507, 'gamma': 4.802750374089542, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8366\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8366 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 0.3738720166607507, 'gamma': 4.802750374089542, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8903\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 6: - Random Seed: 9266\n",
      "100%|██████████| 220/220 [06:06<00:00,  1.66s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 0.5987067257712952, 'gamma': 1.4782416072581532, 'kernel': 1}\n",
      "{'C': 0.5987067257712952, 'gamma': 1.4782416072581532, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7582\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8645\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 7: - Random Seed: 2528\n",
      "100%|██████████| 220/220 [06:07<00:00,  1.67s/trial, best loss: -0.8129032258064516]\n",
      "{'C': 11.523029422500166, 'gamma': 3.0919230312121067, 'kernel': 1}\n",
      "{'C': 11.523029422500166, 'gamma': 3.0919230312121067, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7516\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8194\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 8: - Random Seed: 3147\n",
      "100%|██████████| 220/220 [05:49<00:00,  1.59s/trial, best loss: -0.7903225806451613]\n",
      "{'C': 1.5961361548634532, 'gamma': 8.303755574683246, 'kernel': 1}\n",
      "{'C': 1.5961361548634532, 'gamma': 8.303755574683246, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7386\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 9: - Random Seed: 4438\n",
      "100%|██████████| 220/220 [05:51<00:00,  1.60s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 15.157137295494154, 'gamma': 0.28993815158022507, 'kernel': 1}\n",
      "{'C': 15.157137295494154, 'gamma': 0.28993815158022507, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7974\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8194\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 10: - Random Seed: 9692\n",
      "100%|██████████| 220/220 [05:49<00:00,  1.59s/trial, best loss: -0.8129032258064516]\n",
      "{'C': 0.9126890673013575, 'gamma': 0.2326925454508499, 'kernel': 1}\n",
      "{'C': 0.9126890673013575, 'gamma': 0.2326925454508499, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8968\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 11: - Random Seed: 2949\n",
      "100%|██████████| 220/220 [05:51<00:00,  1.60s/trial, best loss: -0.8]              \n",
      "{'C': 0.899894254017247, 'gamma': 0.2530823696853324, 'kernel': 1}\n",
      "{'C': 0.899894254017247, 'gamma': 0.2530823696853324, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8105\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8968\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 12: - Random Seed: 6978\n",
      "100%|██████████| 220/220 [05:52<00:00,  1.60s/trial, best loss: -0.8064516129032258]\n",
      "{'C': 0.9071337042907945, 'gamma': 0.5177940231259655, 'kernel': 1}\n",
      "{'C': 0.9071337042907945, 'gamma': 0.5177940231259655, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 13: - Random Seed: 6860\n",
      "100%|██████████| 220/220 [05:56<00:00,  1.62s/trial, best loss: -0.8709677419354839]\n",
      "{'C': 0.365610572611295, 'gamma': 3.5148236313556294, 'kernel': 1}\n",
      "{'C': 0.365610572611295, 'gamma': 3.5148236313556294, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8431\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8431 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 0.365610572611295, 'gamma': 3.5148236313556294, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.9161\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[38;5;208mTHAT'S A NEW BEST!!\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 14: - Random Seed: 9099\n",
      "100%|██████████| 220/220 [05:51<00:00,  1.60s/trial, best loss: -0.7677419354838709]\n",
      "{'C': 13.429047189597693, 'gamma': 15.148543543350147, 'kernel': 1}\n",
      "{'C': 13.429047189597693, 'gamma': 15.148543543350147, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8562\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8562 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 13.429047189597693, 'gamma': 15.148543543350147, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.9032\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 15: - Random Seed: 6612\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.7741935483870968]\n",
      "{'C': 2.108868323500124, 'gamma': 0.13362793978503443, 'kernel': 1}\n",
      "{'C': 2.108868323500124, 'gamma': 0.13362793978503443, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8170\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8710\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 16: - Random Seed: 8220\n",
      "100%|██████████| 220/220 [05:45<00:00,  1.57s/trial, best loss: -0.7677419354838709]\n",
      "{'C': 0.39838900552030065, 'gamma': 6.153004463514457, 'kernel': 1}\n",
      "{'C': 0.39838900552030065, 'gamma': 6.153004463514457, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8497\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8645\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 17: - Random Seed: 2217\n",
      "100%|██████████| 220/220 [05:40<00:00,  1.55s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 0.3890042118344039, 'gamma': 1.8841429769553395, 'kernel': 1}\n",
      "{'C': 0.3890042118344039, 'gamma': 1.8841429769553395, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8170\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 18: - Random Seed: 5762\n",
      "100%|██████████| 220/220 [05:39<00:00,  1.54s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 1.1705455961708222, 'gamma': 2.0263076842179557, 'kernel': 1}\n",
      "{'C': 1.1705455961708222, 'gamma': 2.0263076842179557, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7582\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8581\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 19: - Random Seed: 7479\n",
      "100%|██████████| 220/220 [05:44<00:00,  1.57s/trial, best loss: -0.7483870967741936]\n",
      "{'C': 7.738615073959873, 'gamma': 0.21485555049005545, 'kernel': 1}\n",
      "{'C': 7.738615073959873, 'gamma': 0.21485555049005545, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7647\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 20: - Random Seed: 51\n",
      "100%|██████████| 220/220 [05:42<00:00,  1.56s/trial, best loss: -0.8064516129032259]\n",
      "{'C': 0.10874254960645367, 'gamma': 2.1422606502907953, 'kernel': 1}\n",
      "{'C': 0.10874254960645367, 'gamma': 2.1422606502907953, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8758\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8758 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 0.10874254960645367, 'gamma': 2.1422606502907953, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 21: - Random Seed: 3990\n",
      "100%|██████████| 220/220 [05:44<00:00,  1.56s/trial, best loss: -0.8032258064516129]\n",
      "{'C': 1.6138613367078491, 'gamma': 1.7080637240955467, 'kernel': 1}\n",
      "{'C': 1.6138613367078491, 'gamma': 1.7080637240955467, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8431\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 22: - Random Seed: 3783\n",
      "100%|██████████| 220/220 [05:46<00:00,  1.57s/trial, best loss: -0.7838709677419355]\n",
      "{'C': 0.7952038646093491, 'gamma': 6.270452986833778, 'kernel': 1}\n",
      "{'C': 0.7952038646093491, 'gamma': 6.270452986833778, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8627\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8452\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 23: - Random Seed: 5635\n",
      "100%|██████████| 220/220 [05:41<00:00,  1.55s/trial, best loss: -0.8161290322580645]\n",
      "{'C': 0.5791096832698643, 'gamma': 4.175542517341453, 'kernel': 1}\n",
      "{'C': 0.5791096832698643, 'gamma': 4.175542517341453, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8562\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7742\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 24: - Random Seed: 4896\n",
      "100%|██████████| 220/220 [05:41<00:00,  1.55s/trial, best loss: -0.8290322580645161]\n",
      "{'C': 0.7412984356736236, 'gamma': 10.737117716807914, 'kernel': 1}\n",
      "{'C': 0.7412984356736236, 'gamma': 10.737117716807914, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8366\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 25: - Random Seed: 9688\n",
      "100%|██████████| 220/220 [05:46<00:00,  1.57s/trial, best loss: -0.8]             \n",
      "{'C': 3.488376933372153, 'gamma': 0.19530996837898423, 'kernel': 1}\n",
      "{'C': 3.488376933372153, 'gamma': 0.19530996837898423, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7451\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8774\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 26: - Random Seed: 7952\n",
      "100%|██████████| 220/220 [05:45<00:00,  1.57s/trial, best loss: -0.7806451612903226]\n",
      "{'C': 0.23345526079994125, 'gamma': 3.321885091116489, 'kernel': 1}\n",
      "{'C': 0.23345526079994125, 'gamma': 3.321885091116489, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7843\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8387\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 27: - Random Seed: 2853\n",
      "100%|██████████| 220/220 [05:44<00:00,  1.56s/trial, best loss: -0.8258064516129032]\n",
      "{'C': 20.000149371502268, 'gamma': 0.9486434887428248, 'kernel': 1}\n",
      "{'C': 20.000149371502268, 'gamma': 0.9486434887428248, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8774\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 28: - Random Seed: 3226\n",
      "100%|██████████| 220/220 [05:43<00:00,  1.56s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 5.776487347479862, 'gamma': 1.763417033875868, 'kernel': 1}\n",
      "{'C': 5.776487347479862, 'gamma': 1.763417033875868, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 29: - Random Seed: 7868\n",
      "100%|██████████| 220/220 [05:46<00:00,  1.57s/trial, best loss: -0.8129032258064516]\n",
      "{'C': 3.0468178133074346, 'gamma': 0.6011584144184162, 'kernel': 1}\n",
      "{'C': 3.0468178133074346, 'gamma': 0.6011584144184162, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.6536\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7935\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 30: - Random Seed: 2324\n",
      "100%|██████████| 220/220 [05:40<00:00,  1.55s/trial, best loss: -0.8419354838709677]\n",
      "{'C': 0.5734568658633485, 'gamma': 3.1515769945161565, 'kernel': 1}\n",
      "{'C': 0.5734568658633485, 'gamma': 3.1515769945161565, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7124\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8645\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 31: - Random Seed: 3375\n",
      "100%|██████████| 220/220 [05:46<00:00,  1.58s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 0.11057951144253114, 'gamma': 0.5386262066522096, 'kernel': 1}\n",
      "{'C': 0.11057951144253114, 'gamma': 0.5386262066522096, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8562\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8968\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 32: - Random Seed: 1469\n",
      "100%|██████████| 220/220 [05:46<00:00,  1.57s/trial, best loss: -0.8]             \n",
      "{'C': 0.2871637771418652, 'gamma': 0.0818597626508303, 'kernel': 1}\n",
      "{'C': 0.2871637771418652, 'gamma': 0.0818597626508303, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8366\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8581\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 33: - Random Seed: 9167\n",
      "100%|██████████| 220/220 [05:43<00:00,  1.56s/trial, best loss: -0.8193548387096774]\n",
      "{'C': 1.4179100520978767, 'gamma': 0.2381379929414986, 'kernel': 1}\n",
      "{'C': 1.4179100520978767, 'gamma': 0.2381379929414986, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8039\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8581\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 34: - Random Seed: 7642\n",
      "100%|██████████| 220/220 [05:46<00:00,  1.57s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 2.5043880068631283, 'gamma': 0.09756272424421727, 'kernel': 1}\n",
      "{'C': 2.5043880068631283, 'gamma': 0.09756272424421727, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7386\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8194\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 35: - Random Seed: 148\n",
      "100%|██████████| 220/220 [05:40<00:00,  1.55s/trial, best loss: -0.8161290322580645]\n",
      "{'C': 0.5718759658805487, 'gamma': 0.06292316505796956, 'kernel': 1}\n",
      "{'C': 0.5718759658805487, 'gamma': 0.06292316505796956, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7908\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8710\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 36: - Random Seed: 9284\n",
      "100%|██████████| 220/220 [05:45<00:00,  1.57s/trial, best loss: -0.7741935483870968]\n",
      "{'C': 0.25717170649770965, 'gamma': 0.3633179687980367, 'kernel': 1}\n",
      "{'C': 0.25717170649770965, 'gamma': 0.3633179687980367, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8889\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8889 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 0.25717170649770965, 'gamma': 0.3633179687980367, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 37: - Random Seed: 9238\n",
      "100%|██████████| 220/220 [05:42<00:00,  1.56s/trial, best loss: -0.8]             \n",
      "{'C': 6.859957612210506, 'gamma': 6.732446959543284, 'kernel': 1}\n",
      "{'C': 6.859957612210506, 'gamma': 6.732446959543284, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7712\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 38: - Random Seed: 1805\n",
      "100%|██████████| 220/220 [05:48<00:00,  1.58s/trial, best loss: -0.7870967741935484]\n",
      "{'C': 0.3179955353598323, 'gamma': 0.05188097943421231, 'kernel': 1}\n",
      "{'C': 0.3179955353598323, 'gamma': 0.05188097943421231, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8366\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 39: - Random Seed: 4296\n",
      "100%|██████████| 220/220 [05:48<00:00,  1.58s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 1.8523213598665542, 'gamma': 6.848532451017083, 'kernel': 1}\n",
      "{'C': 1.8523213598665542, 'gamma': 6.848532451017083, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 40: - Random Seed: 5750\n",
      "100%|██████████| 220/220 [05:41<00:00,  1.55s/trial, best loss: -0.7645161290322581]\n",
      "{'C': 3.1626836341378186, 'gamma': 1.1008679416382028, 'kernel': 1}\n",
      "{'C': 3.1626836341378186, 'gamma': 1.1008679416382028, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8693\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7935\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 41: - Random Seed: 4167\n",
      "100%|██████████| 220/220 [05:48<00:00,  1.59s/trial, best loss: -0.8193548387096774]\n",
      "{'C': 0.09352916338073913, 'gamma': 0.08938885036480758, 'kernel': 1}\n",
      "{'C': 0.09352916338073913, 'gamma': 0.08938885036480758, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7386\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8452\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 42: - Random Seed: 6265\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.8032258064516129]\n",
      "{'C': 13.30193432339979, 'gamma': 9.944511930510187, 'kernel': 1}\n",
      "{'C': 13.30193432339979, 'gamma': 9.944511930510187, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8497\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 43: - Random Seed: 4216\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.60s/trial, best loss: -0.7999999999999999]\n",
      "{'C': 5.38294206488734, 'gamma': 0.6751461958929856, 'kernel': 1}\n",
      "{'C': 5.38294206488734, 'gamma': 0.6751461958929856, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7582\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7613\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 44: - Random Seed: 8240\n",
      "100%|██████████| 220/220 [05:52<00:00,  1.60s/trial, best loss: -0.7903225806451613]\n",
      "{'C': 0.20033249552427473, 'gamma': 2.049888055423638, 'kernel': 1}\n",
      "{'C': 0.20033249552427473, 'gamma': 2.049888055423638, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8562\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7806\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 45: - Random Seed: 8839\n",
      "100%|██████████| 220/220 [05:58<00:00,  1.63s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 4.660415087950274, 'gamma': 10.149462896460745, 'kernel': 1}\n",
      "{'C': 4.660415087950274, 'gamma': 10.149462896460745, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8431\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8774\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 46: - Random Seed: 1661\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 0.7456386229800216, 'gamma': 1.0606564301635988, 'kernel': 1}\n",
      "{'C': 0.7456386229800216, 'gamma': 1.0606564301635988, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8065\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 47: - Random Seed: 8902\n",
      "100%|██████████| 220/220 [05:50<00:00,  1.59s/trial, best loss: -0.8161290322580645]\n",
      "{'C': 1.009665379160537, 'gamma': 3.7845440622992546, 'kernel': 1}\n",
      "{'C': 1.009665379160537, 'gamma': 3.7845440622992546, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8105\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8387\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 48: - Random Seed: 2722\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 0.6400577602473388, 'gamma': 11.49626328417145, 'kernel': 1}\n",
      "{'C': 0.6400577602473388, 'gamma': 11.49626328417145, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8954\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.8954 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 0.6400577602473388, 'gamma': 11.49626328417145, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8516\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 49: - Random Seed: 9861\n",
      "100%|██████████| 220/220 [05:54<00:00,  1.61s/trial, best loss: -0.8]             \n",
      "{'C': 1.0097035668330219, 'gamma': 0.3814507957573335, 'kernel': 1}\n",
      "{'C': 1.0097035668330219, 'gamma': 0.3814507957573335, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7451\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8710\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 50: - Random Seed: 1943\n",
      "100%|██████████| 220/220 [05:56<00:00,  1.62s/trial, best loss: -0.8451612903225807]\n",
      "{'C': 13.692642003142911, 'gamma': 11.56830621939566, 'kernel': 1}\n",
      "{'C': 13.692642003142911, 'gamma': 11.56830621939566, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8758\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8774\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 51: - Random Seed: 5555\n",
      "100%|██████████| 220/220 [05:49<00:00,  1.59s/trial, best loss: -0.8032258064516129]\n",
      "{'C': 0.054117875729387616, 'gamma': 0.06438734121816833, 'kernel': 1}\n",
      "{'C': 0.054117875729387616, 'gamma': 0.06438734121816833, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8497\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8323\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 52: - Random Seed: 5271\n",
      "100%|██████████| 220/220 [05:51<00:00,  1.60s/trial, best loss: -0.8419354838709677]\n",
      "{'C': 14.983987930890416, 'gamma': 2.5912476390695023, 'kernel': 1}\n",
      "{'C': 14.983987930890416, 'gamma': 2.5912476390695023, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8516\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 53: - Random Seed: 9035\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 8.713953979084051, 'gamma': 0.10842661776564126, 'kernel': 1}\n",
      "{'C': 8.713953979084051, 'gamma': 0.10842661776564126, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8824\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7806\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 54: - Random Seed: 7815\n",
      "100%|██████████| 220/220 [05:50<00:00,  1.59s/trial, best loss: -0.8064516129032259]\n",
      "{'C': 6.317214796016356, 'gamma': 18.329369838787116, 'kernel': 1}\n",
      "{'C': 6.317214796016356, 'gamma': 18.329369838787116, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8497\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 55: - Random Seed: 675\n",
      "100%|██████████| 220/220 [05:48<00:00,  1.59s/trial, best loss: -0.7967741935483871]\n",
      "{'C': 0.13208215146119387, 'gamma': 10.338927270407979, 'kernel': 1}\n",
      "{'C': 0.13208215146119387, 'gamma': 10.338927270407979, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8301\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.9032\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 56: - Random Seed: 1156\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.60s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 2.3115929574609235, 'gamma': 5.48360369248331, 'kernel': 1}\n",
      "{'C': 2.3115929574609235, 'gamma': 5.48360369248331, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7516\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8387\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 57: - Random Seed: 5557\n",
      "100%|██████████| 220/220 [05:51<00:00,  1.60s/trial, best loss: -0.8064516129032258]\n",
      "{'C': 2.6531087986082773, 'gamma': 5.4245419657943, 'kernel': 1}\n",
      "{'C': 2.6531087986082773, 'gamma': 5.4245419657943, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8039\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8645\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 58: - Random Seed: 4676\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.62s/trial, best loss: -0.8419354838709677]\n",
      "{'C': 1.0258194481713232, 'gamma': 2.9670979788664567, 'kernel': 1}\n",
      "{'C': 1.0258194481713232, 'gamma': 2.9670979788664567, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7908\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8000\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 59: - Random Seed: 696\n",
      "100%|██████████| 220/220 [05:52<00:00,  1.60s/trial, best loss: -0.8387096774193549]\n",
      "{'C': 13.406288418671124, 'gamma': 0.1805605344822604, 'kernel': 1}\n",
      "{'C': 13.406288418671124, 'gamma': 0.1805605344822604, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8235\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 60: - Random Seed: 347\n",
      "100%|██████████| 220/220 [05:50<00:00,  1.59s/trial, best loss: -0.8161290322580645]\n",
      "{'C': 3.209211725031592, 'gamma': 0.05316580592591629, 'kernel': 1}\n",
      "{'C': 3.209211725031592, 'gamma': 0.05316580592591629, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7778\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7806\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 61: - Random Seed: 6874\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.62s/trial, best loss: -0.8161290322580645]\n",
      "{'C': 0.19263738500635633, 'gamma': 3.9958057515489096, 'kernel': 1}\n",
      "{'C': 0.19263738500635633, 'gamma': 3.9958057515489096, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8105\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8387\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 62: - Random Seed: 9722\n",
      "100%|██████████| 220/220 [05:51<00:00,  1.60s/trial, best loss: -0.7870967741935484]\n",
      "{'C': 1.4887384468985234, 'gamma': 0.8805843364319261, 'kernel': 1}\n",
      "{'C': 1.4887384468985234, 'gamma': 0.8805843364319261, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8105\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8452\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 63: - Random Seed: 2570\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.8032258064516129]\n",
      "{'C': 0.07609130212358317, 'gamma': 1.046345738992927, 'kernel': 1}\n",
      "{'C': 0.07609130212358317, 'gamma': 1.046345738992927, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8366\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8258\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 64: - Random Seed: 6937\n",
      "100%|██████████| 220/220 [05:54<00:00,  1.61s/trial, best loss: -0.8]\n",
      "{'C': 0.09339950193136964, 'gamma': 1.2416341831450988, 'kernel': 1}\n",
      "{'C': 0.09339950193136964, 'gamma': 1.2416341831450988, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7516\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7742\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 65: - Random Seed: 5931\n",
      "100%|██████████| 220/220 [05:53<00:00,  1.61s/trial, best loss: -0.7935483870967742]\n",
      "{'C': 5.18844325881446, 'gamma': 1.0701656132770363, 'kernel': 1}\n",
      "{'C': 5.18844325881446, 'gamma': 1.0701656132770363, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8235\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8516\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 66: - Random Seed: 6173\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.61s/trial, best loss: -0.7774193548387097]\n",
      "{'C': 0.263024447094936, 'gamma': 17.094163583524413, 'kernel': 1}\n",
      "{'C': 0.263024447094936, 'gamma': 17.094163583524413, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7843\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8516\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 67: - Random Seed: 4436\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.61s/trial, best loss: -0.8064516129032258]\n",
      "{'C': 0.05367703702566809, 'gamma': 0.9797626500217828, 'kernel': 1}\n",
      "{'C': 0.05367703702566809, 'gamma': 0.9797626500217828, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7843\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8774\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 68: - Random Seed: 3688\n",
      "100%|██████████| 220/220 [05:57<00:00,  1.62s/trial, best loss: -0.7806451612903226]\n",
      "{'C': 0.9318699432023991, 'gamma': 11.810424212673187, 'kernel': 1}\n",
      "{'C': 0.9318699432023991, 'gamma': 11.810424212673187, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7843\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8516\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 69: - Random Seed: 245\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.62s/trial, best loss: -0.7806451612903226]\n",
      "{'C': 3.5855078266443012, 'gamma': 2.484780682836495, 'kernel': 1}\n",
      "{'C': 3.5855078266443012, 'gamma': 2.484780682836495, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7843\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7806\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 70: - Random Seed: 4027\n",
      "100%|██████████| 220/220 [05:54<00:00,  1.61s/trial, best loss: -0.8258064516129032]\n",
      "{'C': 7.770590885259483, 'gamma': 4.371281462122313, 'kernel': 1}\n",
      "{'C': 7.770590885259483, 'gamma': 4.371281462122313, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8301\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8581\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 71: - Random Seed: 7347\n",
      "100%|██████████| 220/220 [05:55<00:00,  1.62s/trial, best loss: -0.832258064516129]\n",
      "{'C': 1.7117511639863334, 'gamma': 0.46051843333344356, 'kernel': 1}\n",
      "{'C': 1.7117511639863334, 'gamma': 0.46051843333344356, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8562\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 72: - Random Seed: 905\n",
      "100%|██████████| 220/220 [05:56<00:00,  1.62s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 1.147280889200989, 'gamma': 0.23189831036982345, 'kernel': 1}\n",
      "{'C': 1.147280889200989, 'gamma': 0.23189831036982345, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8889\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8129\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 73: - Random Seed: 7237\n",
      "100%|██████████| 220/220 [05:52<00:00,  1.60s/trial, best loss: -0.8096774193548387]\n",
      "{'C': 12.31348597410982, 'gamma': 0.4878911876990177, 'kernel': 1}\n",
      "{'C': 12.31348597410982, 'gamma': 0.4878911876990177, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7974\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8839\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 74: - Random Seed: 493\n",
      "100%|██████████| 220/220 [05:52<00:00,  1.60s/trial, best loss: -0.8]             \n",
      "{'C': 2.514067815209179, 'gamma': 0.13302199535496956, 'kernel': 1}\n",
      "{'C': 2.514067815209179, 'gamma': 0.13302199535496956, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.8562\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.8645\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 75: - Random Seed: 1941\n",
      "100%|██████████| 220/220 [05:54<00:00,  1.61s/trial, best loss: -0.8354838709677419]\n",
      "{'C': 0.773383323780612, 'gamma': 1.5241481832788653, 'kernel': 1}\n",
      "{'C': 0.773383323780612, 'gamma': 1.5241481832788653, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7582\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7548\u001b[0m\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "\n",
      "Iteration 76: - Random Seed: 6734\n",
      " 71%|███████▏  | 157/220 [04:17<01:48,  1.72s/trial, best loss: -0.8193548387096774]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, space_eval\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from lxml import etree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cupy as cp\n",
    "from statistics import mean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import random\n",
    "\n",
    "# For visual \n",
    "BOLD = \"\\033[1m\"\n",
    "END = \"\\033[0m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "RED = \"\\033[31m\"\n",
    "ORANGE = \"\\033[38;5;208m\" \n",
    "BLUE = \"\\033[34m\"\n",
    "\n",
    "def load_csv_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_xml_label(xml_path):\n",
    "    tree = etree.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    name = root.find('.//name').text\n",
    "    return name\n",
    "\n",
    "def load_data_from_directory(data_directory):\n",
    "    X = []  # Features\n",
    "    y = []  # Labels\n",
    "\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = data_directory + '/' + filename\n",
    "            xml_path = csv_path.replace('csv', 'xml')\n",
    "            if os.path.exists(xml_path):\n",
    "                X.append(load_csv_data(csv_path))\n",
    "                y.append(load_xml_label(xml_path))\n",
    "            else:\n",
    "                print(\"File not found!\")\n",
    "    print(\"\\nLoading complete!\")\n",
    "    return X, y\n",
    "\n",
    "# Carica i dati dal tuo percorso di directory contenente sia i file .csv che i file .xml\n",
    "data_directory = \"/Users/Riccardo/Desktop/Progetto Scalogrammi/Scalogrammi\"\n",
    "print(\"Loading datas from: \" + data_directory)\n",
    "X, y = load_data_from_directory(data_directory)\n",
    "print(\"Datasets dimension:\")\n",
    "print(f\"X shape: {len(X)}\")\n",
    "print(f\"y shape: {len(y)}\")\n",
    "\n",
    "\n",
    "# I miei data al momento si trovano all'interno di una lista chiamata X contenente i dataFrame creati da ps\n",
    "# per normalizzarli devo scorrere la lista e normalizzarne uno ad uno\n",
    "\n",
    "flat_X = [df.values.flatten() for df in X]\n",
    "X = np.vstack(flat_X)\n",
    "\n",
    "n = 0\n",
    "generations = 100\n",
    "best_accuracy = 0\n",
    "accuracy_test_best = 0\n",
    "\n",
    "while n < generations:\n",
    "\n",
    "    random_seed = random.randint(1, 10000)\n",
    "\n",
    "    # Split dei dati in training set e test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed)\n",
    "    print(\"\\nData splitted into training, validation and test sets\")\n",
    "    # Creazione del validation set\n",
    "    X_train_2, X_val_temp, y_train_temp, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=random_seed)\n",
    "\n",
    "    # Normalizzazione dei dati di training e validation\n",
    "    scaler = StandardScaler()\n",
    "    X_train_norm = scaler.fit_transform(X_train)\n",
    "    X_test_norm = scaler.fit_transform(X_test)\n",
    "    X_train_temp = scaler.fit_transform(X_train_2)\n",
    "    X_val = scaler.fit_transform(X_val_temp)\n",
    "\n",
    "    np.savetxt('X_train_norm.csv', X_train_norm, delimiter=',') # <---| Salvo i dati per effettuare un controllo su di essi e che non vi siano irregolarità |\n",
    "\n",
    "    # Creiamo il classificatore SVM\n",
    "    svm_classifier = SVC(random_state=random_seed) #Classifier\n",
    "\n",
    "    # param_grid for bayesian optimization\n",
    "    param_grid_bs = {\n",
    "\n",
    "        'C': hp.loguniform('C', -3, 3),\n",
    "        'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']), # Tipo di kernel utilizzato dalla SVM [linear, poly, rbf, sigmoid, precomputed]\n",
    "        'gamma': hp.loguniform('gamma', -3, 3), # Aggiungi i valori per l'iperparametro \"gamma\"\n",
    "        # 'C': hp.uniform('C', 1.5, 3), altri parametri\n",
    "        # 'gamma': hp.uniform('gamma', 9, 11), altri parametri\n",
    "    }\n",
    "\n",
    "    scoring = ['accuracy']\n",
    "\n",
    "    # Bayesian optimization for Hyper-parameters tuning\n",
    "\n",
    "    # Funzione obiettivo\n",
    "    def objective(param, X, y):\n",
    "\n",
    "        svc = SVC(**param)\n",
    "        scores = cross_val_score(svc, X, y, cv=5, scoring='accuracy', n_jobs=-1, error_score='raise') # Cross-validation = 5, n_jobs = -1 means use all cores avaiables\n",
    "\n",
    "        # best\n",
    "        best_score = mean(scores)\n",
    "\n",
    "        # min loss\n",
    "        loss = -best_score\n",
    "\n",
    "        return {'loss':loss, 'params':param, 'status':STATUS_OK}\n",
    "\n",
    "\n",
    "    # Trials tracking process\n",
    "    bayes_trials = Trials() \n",
    "    \n",
    "    '''The model-based optimization algorithms used by hyperopt's fmin function work by analyzing samples of a response surface--a\n",
    "      history of what points in the search space were tested, and what was discovered by those tests. \n",
    "      A Trials instance stores that history and makes it available to fmin and to the various optimization algorithms.'''\n",
    "\n",
    "    print(f'\\n\\nIteration {n + 1}: - Random Seed: {random_seed}')\n",
    "\n",
    "    # Optimization\n",
    "    best = fmin(fn = lambda param: objective(param, X_train_temp, y_train_temp), #Pass X_train, y_train as parameters to objective\n",
    "                    space = param_grid_bs, algo = tpe.suggest, max_evals = 220, trials = bayes_trials)\n",
    "\n",
    "    # index best parameters\n",
    "    print(best)\n",
    "\n",
    "    # value best parameters\n",
    "    print(space_eval(param_grid_bs, best))\n",
    "\n",
    "    # Training using the best parameters found by the bayesian optimization\n",
    "    svc_bs = SVC(C=space_eval(param_grid_bs, best)['C'], gamma=space_eval(param_grid_bs, best)['gamma'], kernel=space_eval(param_grid_bs, best)['kernel']).fit(X_train_temp, y_train_temp)\n",
    "\n",
    "    # print best accuracy for testing\n",
    "    accuracy_val = svc_bs.score(X_val, y_val)\n",
    "    print(f'The accuracy score for the validation dataset is {accuracy_val:.4f}') \n",
    "\n",
    "    # All-time best validation set score\n",
    "    if accuracy_val > best_accuracy:\n",
    "        best_accuracy = accuracy_val\n",
    "        best_hyperparameters = space_eval(param_grid_bs, best)\n",
    "        accuracy_part = f'{BOLD}{GREEN}The best accuracy on the validation set is {END}'\n",
    "        accuracy_value = f'{BOLD}{RED}{best_accuracy:.4f} {END}'\n",
    "        hyperparameters_part = f'{BOLD}{GREEN}with hyperparameters: {END}'\n",
    "        hyperparameters_value = f'{BOLD}{RED}{best_hyperparameters}{END}'\n",
    "        # Found a new best: best_accuracy = 0.9247, with hyperparameters: {'C': 1.661179450996574, 'gamma': 10.643118612567408, 'kernel': 'poly'}\n",
    "        # just a comment with a good accuracy\n",
    "\n",
    "        formatted_sentence = accuracy_part + accuracy_value + hyperparameters_part + hyperparameters_value\n",
    "\n",
    "        print(formatted_sentence)\n",
    "\n",
    "    svc_test = SVC(C = best_hyperparameters['C'], gamma = best_hyperparameters['gamma'], kernel = best_hyperparameters['kernel'])\n",
    "    svc_test.fit(X_train_norm, y_train)\n",
    "    y_pred = svc_test.predict(X_test_norm)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    print(f'\\nThe accuracy score on the test dataset, with this hyper-parameters is {BOLD}{BLUE}{accuracy_test:.4f}{END}')\n",
    "    \n",
    "    # All-time best test set score\n",
    "    if accuracy_test > accuracy_test_best:\n",
    "        accuracy_test_best = accuracy_test\n",
    "        best_hyperparameters_test = best_hyperparameters\n",
    "        print(f'\\n{BOLD}{ORANGE}THAT\\'S A NEW BEST!!{END}')\n",
    "\n",
    "\n",
    "    n = n + 1\n",
    "    ###############################################################################################\n",
    "\n",
    "    # 300:'C': 1.6530246210180544, 'gamma': 9.301052005520031, 'kernel': 'poly', accuracy 0.9022\n",
    "    # Evaluate the best hyperparam on the test data set\n",
    "\n",
    "\n",
    "#Salvataggio degli iperprametri con la maggior accuratezza trovata dal bayesian\n",
    "param_grid_bs_str = json.dumps(best_hyperparameters_test)\n",
    "file_name = \"best_result.txt\"\n",
    "with open(file_name, 'a') as file:\n",
    "    file.write(\"\\n\" + str(len(X)) + \": \" + param_grid_bs_str + \", accuracy \" + str(accuracy_test_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****SENZA LOOP****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datas from: /Users/Riccardo/Desktop/Progetto Scalogrammi/Scalogrammi\n",
      "\n",
      "Loading complete!\n",
      "Datasets dimension:\n",
      "X shape: 618\n",
      "y shape: 618\n",
      "\n",
      "Data splitted into training, validation and test sets\n",
      "\n",
      "Starting normalization of each dataFrame (train, test)\n",
      "\n",
      "Normalization completed!\n",
      "100%|██████████| 500/500 [20:48<00:00,  2.50s/trial, best loss: -0.8405063291139241]\n",
      "{'C': 2.4877215934325068, 'gamma': 5.234752627077685, 'kernel': 1}\n",
      "{'C': 2.4877215934325068, 'gamma': 5.234752627077685, 'kernel': 'poly'}\n",
      "The accuracy score for the validation dataset is 0.7677\n",
      "\u001b[1m\u001b[32mThe best accuracy on the validation set is \u001b[0m\u001b[1m\u001b[31m0.7677 \u001b[0m\u001b[1m\u001b[32mwith hyperparameters: \u001b[0m\u001b[1m\u001b[31m{'C': 2.4877215934325068, 'gamma': 5.234752627077685, 'kernel': 'poly'}\u001b[0m\n",
      "\n",
      "The accuracy score on the test dataset, with this hyper-parameters is \u001b[1m\u001b[34m0.7984\u001b[0m\n",
      "\n",
      " \u001b[1m\u001b[38;5;208mTHAT'S A NEW BEST!!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, space_eval\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from lxml import etree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cupy as cp\n",
    "from statistics import mean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "# For visual \n",
    "BOLD = \"\\033[1m\"\n",
    "END = \"\\033[0m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "RED = \"\\033[31m\"\n",
    "ORANGE = \"\\033[38;5;208m\" \n",
    "BLUE = \"\\033[34m\"\n",
    "\n",
    "def load_csv_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_xml_label(xml_path):\n",
    "    tree = etree.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    name = root.find('.//name').text\n",
    "    return name\n",
    "\n",
    "def load_data_from_directory(data_directory):\n",
    "    X = []  # Features\n",
    "    y = []  # Labels\n",
    "\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = data_directory + '/' + filename\n",
    "            xml_path = csv_path.replace('csv', 'xml')\n",
    "            if os.path.exists(xml_path):\n",
    "                X.append(load_csv_data(csv_path))\n",
    "                y.append(load_xml_label(xml_path))\n",
    "            else:\n",
    "                print(\"File not found!\")\n",
    "    print(\"\\nLoading complete!\")\n",
    "    return X, y\n",
    "\n",
    "# Carica i dati dal tuo percorso di directory contenente sia i file .csv che i file .xml\n",
    "data_directory = \"/Users/Riccardo/Desktop/Progetto Scalogrammi/Scalogrammi\"\n",
    "print(\"Loading datas from: \" + data_directory)\n",
    "X, y = load_data_from_directory(data_directory)\n",
    "print(\"Datasets dimension:\")\n",
    "print(f\"X shape: {len(X)}\")\n",
    "print(f\"y shape: {len(y)}\")\n",
    "\n",
    "\n",
    "# I miei data al momento si trovano all'interno di una lista chiamata X contenente i dataFrame creati da ps\n",
    "# per normalizzarli devo scorrere la lista e normalizzarne uno ad uno\n",
    "\n",
    "flat_X = [df.values.flatten() for df in X]\n",
    "X = np.vstack(flat_X)\n",
    "\n",
    "random_seed = random.randint(1, 10000)\n",
    "\n",
    "# Split dei dati in training set e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_seed)\n",
    "X_train_2, X_val_temp, y_train_temp, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=random_seed)\n",
    "print(\"\\nData splitted into training, validation and test sets\")\n",
    "\n",
    "# Utilizziamo la TF-IDF per vettorizzare i dati CSV\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "# X_val_vectorized = vectorizer.transform(X_val)\n",
    "# X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "#Normalizzo i parametri con vettorizzazione\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_vectorized.toarray())  # Converto da matrice ad array\n",
    "# X_val_scaled = scaler.transform(X_val_vectorized.toarray()) # Converto da matrice ad array\n",
    "# X_test_scaled = scaler.transform(X_test_vectorized.toarray())\n",
    "\n",
    "\n",
    "# Normalizzazione senza vettorizzazione\n",
    "print(\"\\nStarting normalization of each dataFrame (train, test)\")\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.fit_transform(X_test)\n",
    "X_train_temp = scaler.fit_transform(X_train_2)\n",
    "X_val = scaler.fit_transform(X_val_temp)\n",
    "\n",
    "print(\"\\nNormalization completed!\")\n",
    "\n",
    "np.savetxt('X_train_norm.csv', X_train_norm, delimiter=',')\n",
    "\n",
    "# print(\"Normalization completed successfully!\")\n",
    "# Creiamo il classificatore SVM\n",
    "\n",
    "svm_classifier = SVC(random_state=random_seed) #Classifier\n",
    "\n",
    "# Definisco gli iperparametri \n",
    "gamma_range = np.logspace(-10, 10, 21)\n",
    "C_range = np.logspace(-10, 10, 21)\n",
    "\n",
    "# param_grid for bayesian optimization\n",
    "param_grid_bs = {\n",
    "\n",
    "    'C': hp.loguniform('C', -3, 3),\n",
    "    'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']), # Tipo di kernel utilizzato dalla SVM\n",
    "    # linear, poly, rbf, sigmoid, precomputed \n",
    "    'gamma': hp.loguniform('gamma', -3, 3), # Aggiungi i valori per l'iperparametro \"gamma\"\n",
    "\n",
    "}\n",
    "\n",
    "scoring = ['accuracy']\n",
    "\n",
    "# Cross validation\n",
    "################################################################################################\n",
    "# Questo frammento di codice è utilizzato per una K-Fold cross-validation\n",
    "# k_fold = sk.model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_search = GridSearchCV(svm_classifier, param_grid, cv=k_fold)\n",
    "\n",
    "\n",
    "# Questo frammento di codice è utilizzato per la cross-validation classica \n",
    "# Cerco di trovare i migliori iperparametri attraverso una cross-validation sul training set  \n",
    "#   \n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)  \n",
    "\n",
    "# grid_search = GridSearchCV(svm_classifier, param_grid, cv=kfold, refit='accuracy', n_jobs=-1, scoring=scoring, verbose=3) # Verbose stampa il tempo di computazione per ogni fol\n",
    "\n",
    "\n",
    "# grid_result = grid_search.fit(X_train_norm, y_train)\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# Bayesian optimization for Hyper-parameters tuning\n",
    "\n",
    "# Funzione obiettivo\n",
    "def objective(param, X, y):\n",
    "\n",
    "    svc = SVC(**param)\n",
    "    scores = cross_val_score(svc, X, y, cv=5, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "    # best\n",
    "    best_score = mean(scores)\n",
    "\n",
    "    # min loss\n",
    "    loss = -best_score\n",
    "\n",
    "    return {'loss':loss, 'params':param, 'status':STATUS_OK}\n",
    "\n",
    "\n",
    "# Trials tracking process\n",
    "bayes_trials = Trials()\n",
    "\n",
    "\n",
    "# Optimization\n",
    "best = fmin(fn = lambda param: objective(param, X_train_temp, y_train_temp), #Pass X_train, y_train as parameters to objective\n",
    "                 space = param_grid_bs, algo = tpe.suggest, max_evals = 500, trials = bayes_trials)\n",
    "\n",
    "# index best parameters\n",
    "print(best)\n",
    "\n",
    "# value best parameters\n",
    "print(space_eval(param_grid_bs, best))\n",
    "\n",
    "# Training using the best parameters found by the bayesian optimization\n",
    "svc_bs = SVC(C=space_eval(param_grid_bs, best)['C'], gamma=space_eval(param_grid_bs, best)['gamma'], kernel=space_eval(param_grid_bs, best)['kernel']).fit(X_train_temp, y_train_temp)\n",
    "\n",
    "# print best accuracy for testing\n",
    "accuracy_val = svc_bs.score(X_val, y_val)\n",
    "print(f'The accuracy score for the validation dataset is {accuracy_val:.4f}') \n",
    "\n",
    "\n",
    "best_accuracy = accuracy_val\n",
    "best_hyperparameters = space_eval(param_grid_bs, best)\n",
    "accuracy_part = f'{BOLD}{GREEN}The best accuracy on the validation set is {END}'\n",
    "accuracy_value = f'{BOLD}{RED}{best_accuracy:.4f} {END}'\n",
    "hyperparameters_part = f'{BOLD}{GREEN}with hyperparameters: {END}'\n",
    "hyperparameters_value = f'{BOLD}{RED}{best_hyperparameters}{END}'\n",
    "# Found a new best: best_accuracy = 0.9247, with hyperparameters: {'C': 1.661179450996574, 'gamma': 10.643118612567408, 'kernel': 'poly'}\n",
    "# just a comment with a good accuracy\n",
    "\n",
    "formatted_sentence = accuracy_part + accuracy_value + hyperparameters_part + hyperparameters_value\n",
    "\n",
    "print(formatted_sentence)\n",
    "\n",
    "svc_test = SVC(C = best_hyperparameters['C'], gamma = best_hyperparameters['gamma'], kernel = best_hyperparameters['kernel'])\n",
    "svc_test.fit(X_train_norm, y_train)\n",
    "y_pred = svc_test.predict(X_test_norm)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nThe accuracy score on the test dataset, with this hyper-parameters is {BOLD}{BLUE}{accuracy_test:.4f}{END}')\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "# 300:'C': 1.6530246210180544, 'gamma': 9.301052005520031, 'kernel': 'poly', accuracy 0.9022\n",
    "# Evaluate the best hyperparam on the test data set\n",
    "\n",
    "best_accuracy_test = 0\n",
    "#Salvataggio degli iperprametri con la maggior accuratezza trovata dal bayesian\n",
    "param_grid_bs_str = json.dumps(best_hyperparameters)\n",
    "file_name = \"best_result.txt\"\n",
    "with open(file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        accuracy_match = re.search(r'accuracy ([\\d.]+)', line)\n",
    "        if accuracy_match:\n",
    "            accuracy_in_file = float(accuracy_match.group(1))\n",
    "            if accuracy_test > accuracy_in_file:\n",
    "                best_accuracy_test = accuracy_test\n",
    "                print(f'\\n {BOLD}{ORANGE}THAT\\'S A NEW BEST!!{END}')\n",
    "                break\n",
    "\n",
    "with open(file_name, 'a') as file:\n",
    "    file.write(\"\\n\" + str(len(X)) + \": \" + param_grid_bs_str + \", accuracy \" + str(accuracy_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datas from: /Users/Riccardo/Desktop/Progetto Scalogrammi/Scalogrammi\n",
      "\n",
      "Loading complete!\n",
      "Datasets dimension:\n",
      "X shape: 618\n",
      "y shape: 618\n",
      "\n",
      "Data splitted into training and test sets\n",
      "\n",
      "Starting normalization of each dataFrame (train, test)\n",
      "\n",
      "...\n",
      "\n",
      "Normalization completed!\n",
      "100%|██████████| 600/600 [19:24<00:00,  1.94s/trial, best loss: -0.7991481636642928]\n",
      "{'C': 1.9418042739186285, 'gamma': 10.407294205118141, 'kernel': 1}\n",
      "{'C': 1.9418042739186285, 'gamma': 10.407294205118141, 'kernel': 'poly'}\n",
      "The accuracy score for the testing dataset is 0.8968\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, space_eval\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from lxml import etree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cupy as cp\n",
    "from statistics import mean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "\n",
    "def load_csv_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_xml_label(xml_path):\n",
    "    tree = etree.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    name = root.find('.//name').text\n",
    "    return name\n",
    "\n",
    "def load_data_from_directory(data_directory):\n",
    "    X = []  # Features\n",
    "    y = []  # Labels\n",
    "\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = data_directory + '/' + filename\n",
    "            xml_path = csv_path.replace('csv', 'xml')\n",
    "            if os.path.exists(xml_path):\n",
    "                X.append(load_csv_data(csv_path))\n",
    "                y.append(load_xml_label(xml_path))\n",
    "            else:\n",
    "                print(\"File not found!\")\n",
    "    print(\"\\nLoading complete!\")\n",
    "    return X, y\n",
    "\n",
    "# Carica i dati dal tuo percorso di directory contenente sia i file .csv che i file .xml\n",
    "data_directory = \"/Users/Riccardo/Desktop/Progetto Scalogrammi/Scalogrammi\"\n",
    "print(\"Loading datas from: \" + data_directory)\n",
    "X, y = load_data_from_directory(data_directory)\n",
    "print(\"Datasets dimension:\")\n",
    "print(f\"X shape: {len(X)}\")\n",
    "print(f\"y shape: {len(y)}\")\n",
    "\n",
    "\n",
    "# I miei data al momento si trovano all'interno di una lista chiamata X contenente i dataFrame creati da ps\n",
    "# per normalizzarli devo scorrere la lista e normalizzarne uno ad uno\n",
    "\n",
    "flat_X = [df.values.flatten() for df in X]\n",
    "X = np.vstack(flat_X)\n",
    "\n",
    "# Split dei dati in training set e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "print(\"\\nData splitted into training and test sets\")\n",
    "\n",
    "# Split del training set in training set e validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "# Utilizziamo la TF-IDF per vettorizzare i dati CSV\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "# X_val_vectorized = vectorizer.transform(X_val)\n",
    "# X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "#Normalizzo i parametri con vettorizzazione\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_vectorized.toarray())  # Converto da matrice ad array\n",
    "# X_val_scaled = scaler.transform(X_val_vectorized.toarray()) # Converto da matrice ad array\n",
    "# X_test_scaled = scaler.transform(X_test_vectorized.toarray())\n",
    "\n",
    "\n",
    "# Normalizzazione senza vettorizzazione\n",
    "print(\"\\nStarting normalization of each dataFrame (train, test)\")\n",
    "scaler = StandardScaler()\n",
    "# X_val_scaled = scaler.transform(X_val) # Converto da matrice ad array\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "print(\"\\n...\")\n",
    "X_test_norm = scaler.fit_transform(X_test)\n",
    "\n",
    "print(\"\\nNormalization completed!\")\n",
    "\n",
    "np.savetxt('X_train_norm.csv', X_train_norm, delimiter=',')\n",
    "\n",
    "# print(\"Normalization completed successfully!\")\n",
    "# Creiamo il classificatore SVM\n",
    "\n",
    "svm_classifier = SVC(random_state=1) #Classifier\n",
    "\n",
    "# Definisco gli iperparametri \n",
    "gamma_range = np.logspace(-10, 10, 21)\n",
    "C_range = np.logspace(-10, 10, 21)\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "\n",
    "    'C': np.logspace(-3, 2, 6),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], # Tipo di kernel utilizzato dalla SVM\n",
    "    # linear, poly, rbf, sigmoid, precomputed \n",
    "    'gamma': gamma_range.tolist() +  ['auto', 'scale'] # Aggiungi i valori per l'iperparametro \"gamma\"\n",
    "    \n",
    "}'''\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "    'C':np.logspace(-3, 2, 6),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], # Tipo di kernel utilizzato dalla SVM\n",
    "    # linear, poly, rbf, sigmoid, precomputed \n",
    "    'gamma':  gamma_range.tolist() + ['scale', 'auto'] # Aggiungi i valori per l'iperparametro \"gamma\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# param_grid for bayesian optimization\n",
    "param_grid_bs = {\n",
    "\n",
    "    # 'C': hp.loguniform('C', -3, 3),\n",
    "    'C': hp.uniform('C', 1.5, 3),\n",
    "    'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']), # Tipo di kernel utilizzato dalla SVM\n",
    "    'gamma': hp.uniform('gamma', 9, 11),\n",
    "    # linear, poly, rbf, sigmoid, precomputed \n",
    "    # 'gamma': hp.loguniform('gamma', -3, 3), # Aggiungi i valori per l'iperparametro \"gamma\"\n",
    "\n",
    "}\n",
    "\n",
    "scoring = ['accuracy']\n",
    "\n",
    "# Cross validation\n",
    "################################################################################################\n",
    "# Questo frammento di codice è utilizzato per una K-Fold cross-validation\n",
    "# k_fold = sk.model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_search = GridSearchCV(svm_classifier, param_grid, cv=k_fold)\n",
    "\n",
    "\n",
    "# Questo frammento di codice è utilizzato per la cross-validation classica \n",
    "# Cerco di trovare i migliori iperparametri attraverso una cross-validation sul training set  \n",
    "#   \n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=32)  \n",
    "\n",
    "# grid_search = GridSearchCV(svm_classifier, param_grid, cv=kfold, refit='accuracy', n_jobs=-1, scoring=scoring, verbose=3) # Verbose stampa il tempo di computazione per ogni fol\n",
    "\n",
    "\n",
    "# grid_result = grid_search.fit(X_train_norm, y_train)\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# Bayesian optimization for Hyper-parameters tuning\n",
    "\n",
    "# Funzione obiettivo\n",
    "def objective(param):\n",
    "\n",
    "    svc = SVC(**param)\n",
    "    scores = cross_val_score(svc, X_train_norm, y_train, cv=kfold, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "    # best\n",
    "    best_score = mean(scores)\n",
    "\n",
    "    # min loss\n",
    "    loss = -best_score\n",
    "\n",
    "    return {'loss':loss, 'params':param, 'status':STATUS_OK}\n",
    "\n",
    "# Trials tracking process\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Optimization\n",
    "best = fmin(fn = objective, space = param_grid_bs, algo = tpe.suggest, max_evals = 600, trials = bayes_trials)\n",
    "\n",
    "# index best parameters\n",
    "print(best)\n",
    "\n",
    "# value best parameters\n",
    "print(space_eval(param_grid_bs, best))\n",
    "\n",
    "# Training using the best parameters found by the bayesian optimization\n",
    "svc_bs = SVC(C=space_eval(param_grid_bs, best)['C'], gamma=space_eval(param_grid_bs, best)['gamma'], kernel=space_eval(param_grid_bs, best)['kernel']).fit(X_train_norm, y_train)\n",
    "\n",
    "# print best accuracy for testing\n",
    "accuracy_test = svc_bs.score(X_test_norm, y_test)\n",
    "print(f'The accuracy score for the testing dataset is {accuracy_test:.4f}') \n",
    "###############################################################################################\n",
    "\n",
    "# 300:'C': 1.6530246210180544, 'gamma': 9.301052005520031, 'kernel': 'poly', accuracy 0.9022\n",
    "\n",
    "#Salvataggio degli iperprametri con la maggior accuratezza trovata dal bayesian\n",
    "param_grid_bs_str = json.dumps(space_eval(param_grid_bs, best))\n",
    "file_name = \"best_result.txt\"\n",
    "with open(file_name, 'a') as file:\n",
    "    file.write(\"\\n\" + str(len(X)) + \": \" + param_grid_bs_str + \", accuracy \" + str(accuracy_test))\n",
    "\n",
    "# Print the best accuracy score for the training dataset\n",
    "## print(f'The best accuracy score for the training dataset is {grid_result.best_score_:.4f}')\n",
    "# Print the hyperparameters for the best score\n",
    "## print(f'The best hyperparameters are {grid_result.best_params_}')\n",
    "# Print the best accuracy score for the testing dataset\n",
    "## print(f'The accuracy score for the testing dataset is {grid_search.score(X_test_norm, y_test):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
